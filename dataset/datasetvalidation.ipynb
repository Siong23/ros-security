{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW-pjcd9etDH",
        "outputId": "1b0ee973-7813-4be9-fa0a-11be807b7330"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features order: ['Src Port', 'Dst Port', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\n"
          ]
        }
      ],
      "source": [
        "from joblib import load\n",
        "import pandas as pd\n",
        "\n",
        "# Load model, scaler, and features\n",
        "model = load(\"model.joblib\")\n",
        "scaler = load(\"scaler.joblib\")   # skip if you didn’t save scaler\n",
        "\n",
        "with open(\"features.txt\") as f:\n",
        "    features = [line.strip() for line in f]\n",
        "\n",
        "print(\"Features order:\", features)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model expects:\", features[:10], \"...\")  # first 10 expected features\n",
        "print(\"CSV has:\", list(new_data.columns)[:10], \"...\")  # first 10 columns from CSV\n",
        "\n",
        "missing = set(features) - set(new_data.columns)\n",
        "extra = set(new_data.columns) - set(features)\n",
        "\n",
        "print(\"Missing in CSV:\", missing)\n",
        "print(\"Extra in CSV:\", extra)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlwI-Z0Ze50K",
        "outputId": "ff46c0ae-a30b-4548-cbe6-7d7d7bd8da37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model expects: ['Src Port', 'Dst Port', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean'] ...\n",
            "CSV has: ['Src Port', 'Dst Port', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean'] ...\n",
            "Missing in CSV: set()\n",
            "Extra in CSV: set()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Force reordering of columns to match training order\n",
        "new_data = new_data.reindex(columns=features)\n"
      ],
      "metadata": {
        "id": "W94QFhJngc9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only model's features (drop all others)\n",
        "new_data = new_data.loc[:, new_data.columns.intersection(features)]\n",
        "\n",
        "# Reorder columns to exactly match training\n",
        "new_data = new_data.reindex(columns=features)"
      ],
      "metadata": {
        "id": "o0lgvbMigWyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Expected features:\", features)\n",
        "print(\"New data columns :\", list(new_data.columns))\n",
        "print(\"Shape of new_data:\", new_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3sKIUE0gjzX",
        "outputId": "071923e0-b684-4aa1-b7eb-8355a0138deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected features: ['Src Port', 'Dst Port', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\n",
            "New data columns : ['Src Port', 'Dst Port', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\n",
            "Shape of new_data: (845, 78)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = new_data[features].copy()\n"
      ],
      "metadata": {
        "id": "cX-FYFrPgzp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean up column names (remove hidden spaces etc.)\n",
        "new_data.columns = new_data.columns.str.strip()\n",
        "\n",
        "# Now force subset to ONLY training features\n",
        "new_data = new_data.loc[:, features]\n",
        "\n",
        "# Confirm\n",
        "print(\"Training features:\", features)\n",
        "print(\"New data columns:\", list(new_data.columns))\n",
        "print(\"Same?\", features == list(new_data.columns))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjf1pWNBg0V7",
        "outputId": "0566457c-c2e2-4fe7-c047-9030cdf90a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training features: ['Src Port', 'Dst Port', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\n",
            "New data columns: ['Src Port', 'Dst Port', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\n",
            "Same? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Scaler feature names:\", list(scaler.feature_names_in_))\n",
        "print(\"New data columns    :\", list(new_data.columns))\n",
        "print(\"Match?\", list(scaler.feature_names_in_) == list(new_data.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExIDi6Nlg6Zv",
        "outputId": "a68faaa8-00e9-48a0-f07d-b655f1c60e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaler feature names: ['Dst Port', 'Src Port', 'Bwd Header Len', 'Bwd Pkts/s', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Pkt Len Mean', 'Flow Pkts/s', 'Pkt Size Avg', 'Flow Duration', 'Pkt Len Std', 'Pkt Len Var', 'Flow IAT Mean', 'Bwd IAT Max', 'Subflow Bwd Byts', 'TotLen Bwd Pkts', 'Bwd Seg Size Avg', 'Bwd Pkt Len Mean', 'Flow IAT Max', 'Init Bwd Win Byts', 'Pkt Len Max', 'Flow Byts/s', 'Fwd Pkts/s', 'Fwd Header Len', 'Flow IAT Std', 'Subflow Bwd Pkts', 'Tot Bwd Pkts', 'Bwd IAT Min', 'Bwd Pkt Len Max', 'Bwd IAT Std', 'Tot Fwd Pkts', 'Subflow Fwd Pkts', 'Bwd Pkt Len Std', 'Flow IAT Min', 'Bwd Pkt Len Min', 'Fwd IAT Mean', 'Fwd IAT Tot', 'Down/Up Ratio', 'Idle Min', 'Idle Mean', 'Idle Max', 'Active Max', 'Fwd IAT Min', 'Active Mean', 'Fwd IAT Max', 'Active Min', 'SYN Flag Cnt', 'ACK Flag Cnt', 'Fwd IAT Std', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean', 'Fwd Seg Size Avg', 'Subflow Fwd Byts', 'TotLen Fwd Pkts', 'PSH Flag Cnt', 'Bwd PSH Flags', 'Idle Std', 'Active Std', 'Fwd Act Data Pkts', 'Fwd Pkt Len Min', 'Fwd Pkt Len Std', 'FIN Flag Cnt', 'Pkt Len Min']\n",
            "New data columns    : ['Src Port', 'Dst Port', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\n",
            "Match? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = new_data.loc[:, scaler.feature_names_in_]\n"
      ],
      "metadata": {
        "id": "t_q9RQovg9rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from joblib import load\n",
        "\n",
        "# === Load model + scaler ===\n",
        "model = load(\"model.joblib\")\n",
        "scaler = load(\"scaler.joblib\")\n",
        "\n",
        "# Expected features from scaler\n",
        "expected_features = list(scaler.feature_names_in_)\n",
        "\n",
        "def prepare_and_predict(csv_file):\n",
        "    # 1. Load CSV\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # 2. Keep only required columns (drop timestamps or extras)\n",
        "    missing = set(expected_features) - set(df.columns)\n",
        "    extra = set(df.columns) - set(expected_features)\n",
        "    print(\"Missing in CSV:\", missing)\n",
        "    print(\"Extra in CSV:\", extra)\n",
        "\n",
        "    df = df.loc[:, expected_features]  # keep only what we need, in correct order\n",
        "\n",
        "    # 3. Clean data\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)  # replace inf with NaN\n",
        "    df = df.fillna(0)  # fill NaN with 0 (safe default, you can change strategy)\n",
        "\n",
        "    # 4. Scale\n",
        "    X_scaled = scaler.transform(df)\n",
        "\n",
        "    # 5. Predict\n",
        "    preds = model.predict(X_scaled)\n",
        "    return preds\n",
        "\n",
        "# === Run prediction on your new CSV ===\n",
        "predictions = prepare_and_predict(\"/content/normalcompiled.pcap_Flow.csv\") # replace data here <-----------------------\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60xSUDe9g_jB",
        "outputId": "c716a8a8-7a57-46fc-c0a0-cd974ab8a27f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing in CSV: set()\n",
            "Extra in CSV: {'Fwd Blk Rate Avg', 'Bwd Pkts/b Avg', 'RST Flag Cnt', 'Fwd Byts/b Avg', 'Fwd Seg Size Min', 'Protocol', 'Init Fwd Win Byts', 'Label', 'ECE Flag Cnt', 'Flow ID', 'Timestamp', 'URG Flag Cnt', 'CWE Flag Count', 'Dst IP', 'Bwd Blk Rate Avg', 'Fwd PSH Flags', 'Fwd URG Flags', 'Src IP', 'Fwd Pkts/b Avg', 'Bwd URG Flags', 'Bwd Byts/b Avg'}\n",
            "[0 0 0 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 0 0 0 0 0 4 0 0 0 0 4 0 0 0 0 0\n",
            " 0 0 0 4 0 0 0 0 0 0 0 0 0 4 0 0 4 0 0 0 0 0 0 0 4 0 0 4 0 0 0 0 0 0 0 0 0\n",
            " 0 4 4 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 4 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 4 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 7 0 0 0 0 0 0 0 4 0 0 4 0 0 0 0 3 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 4 0 0 0 0 0 5 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 4 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 5 0 0 0 5 0 0 0 5 0 0 0 0 0 0 1 0 5 7 5\n",
            " 0 6 0 0 0 1 0 5 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 1 0 0 0 0 0 0 1 0 0\n",
            " 0 1 5 0 5 0 0 0 0 0 0 0 0 0 0 0 4 0 5 0 0 5 0 0 0 1 0 0 0 0 1 2 0 0 6 3 0\n",
            " 3 0 4 5 0 0 4 0 0 4 0 0 6 1 0 0 0 0 7 0 0 0 0 0 0 3 4 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 3 0 0 1 0 0 0 5 0 4 6 0 0 0 3 0 0 0 0 0 0 0 0 0 5 0 0 3 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_and_predict(csv_file, save_cleaned=False):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df = df.loc[:, expected_features]\n",
        "    df = df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "    if save_cleaned:\n",
        "        df.to_csv(\"cleaned_for_model.csv\", index=False)\n",
        "        print(\"Saved cleaned CSV as cleaned_for_model.csv\")\n",
        "\n",
        "    X_scaled = scaler.transform(df)\n",
        "    return model.predict(X_scaled)\n",
        "\n",
        "predictions = prepare_and_predict(\"/content/normalcompiled.pcap_Flow.csv\", save_cleaned=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhrIDDZkhpSI",
        "outputId": "f95d5d85-751b-4179-d16e-20fd50063980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved cleaned CSV as cleaned_for_model.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_and_predict(csv_file, save_cleaned=False):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df = df.loc[:, expected_features]\n",
        "    df = df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "    if save_cleaned:\n",
        "        df.to_csv(\"cleaned_for_model.csv\", index=False)\n",
        "        print(\"Saved cleaned CSV as cleaned_for_model.csv\")\n",
        "\n",
        "    X_scaled = scaler.transform(df)\n",
        "    preds = model.predict(X_scaled)\n",
        "\n",
        "    # Convert numeric predictions into labels\n",
        "    decoded_preds = [label_map.get(p, f\"Unknown({p})\") for p in preds]\n",
        "    return decoded_preds\n"
      ],
      "metadata": {
        "id": "2U2ugmtNh7Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define label mapping (example — adjust if your classes differ!)\n",
        "label_map = {\n",
        "    0: \"BENIGN\",\n",
        "    1: \"Botnet\",\n",
        "    2: \"Brute Force\",\n",
        "    3: \"DDoS\",\n",
        "    4: \"DoS\",\n",
        "    5: \"Infiltration\",\n",
        "    6: \"PortScan\",\n",
        "    7: \"Web Attack\"\n",
        "}\n",
        "\n",
        "def prepare_and_predict(csv_file, save_cleaned=False):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df = df.loc[:, expected_features]\n",
        "    df = df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "    if save_cleaned:\n",
        "        df.to_csv(\"cleaned_for_model.csv\", index=False)\n",
        "        print(\"Saved cleaned CSV as cleaned_for_model.csv\")\n",
        "\n",
        "    X_scaled = scaler.transform(df)\n",
        "    preds = model.predict(X_scaled)\n",
        "\n",
        "    # Convert numeric predictions into labels\n",
        "    decoded_preds = [label_map.get(p, f\"Unknown({p})\") for p in preds]\n",
        "    return decoded_preds\n"
      ],
      "metadata": {
        "id": "vLdjFKz2h83m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = prepare_and_predict(\"/content/normalcompiled.pcap_Flow.csv\", save_cleaned=True)\n",
        "\n",
        "# Print first 10 results\n",
        "print(predictions[:10])\n",
        "\n",
        "# Count benign vs malicious\n",
        "from collections import Counter\n",
        "counts = Counter(predictions)\n",
        "\n",
        "print(\"\\nSummary of predictions:\")\n",
        "print(counts)\n",
        "\n",
        "if counts[\"BENIGN\"] == len(predictions):\n",
        "    print(\"✅ All traffic is benign.\")\n",
        "elif counts[\"BENIGN\"] == 0:\n",
        "    print(\"⚠️ All traffic is malicious.\")\n",
        "else:\n",
        "    print(f\"Mix of benign and malicious: {counts['BENIGN']} benign, {len(predictions)-counts['BENIGN']} malicious\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHII0icXibRm",
        "outputId": "55300213-4e8e-4c57-8e94-db67ba32dfc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved cleaned CSV as cleaned_for_model.csv\n",
            "['BENIGN', 'BENIGN', 'BENIGN', 'DoS', 'DoS', 'BENIGN', 'BENIGN', 'BENIGN', 'BENIGN', 'BENIGN']\n",
            "\n",
            "Summary of predictions:\n",
            "Counter({'BENIGN': 755, 'DoS': 43, 'Infiltration': 14, 'DDoS': 11, 'Botnet': 11, 'Web Attack': 6, 'PortScan': 4, 'Brute Force': 1})\n",
            "Mix of benign and malicious: 755 benign, 90 malicious\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = prepare_and_predict(\"/content/path2normal1.pcap_Flow.csv\", save_cleaned=True)\n",
        "\n",
        "# Print first 10 results\n",
        "print(predictions[:10])\n",
        "\n",
        "# Count benign vs malicious\n",
        "from collections import Counter\n",
        "counts = Counter(predictions)\n",
        "\n",
        "print(\"\\nSummary of predictions:\")\n",
        "print(counts)\n",
        "\n",
        "if counts[\"BENIGN\"] == len(predictions):\n",
        "    print(\"✅ All traffic is benign.\")\n",
        "elif counts[\"BENIGN\"] == 0:\n",
        "    print(\"⚠️ All traffic is malicious.\")\n",
        "else:\n",
        "    print(f\"Mix of benign and malicious: {counts['BENIGN']} benign, {len(predictions)-counts['BENIGN']} malicious\")\n"
      ],
      "metadata": {
        "id": "_4_pTQqMleTi",
        "outputId": "0b8dcef9-5924-4ec2-a762-4ecadc571111",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved cleaned CSV as cleaned_for_model.csv\n",
            "['BENIGN', 'DoS', 'BENIGN', 'BENIGN', 'DoS', 'BENIGN', 'BENIGN', 'BENIGN', 'BENIGN', 'BENIGN']\n",
            "\n",
            "Summary of predictions:\n",
            "Counter({'BENIGN': 31, 'DoS': 6, 'PortScan': 1, 'DDoS': 1})\n",
            "Mix of benign and malicious: 31 benign, 8 malicious\n"
          ]
        }
      ]
    }
  ]
}
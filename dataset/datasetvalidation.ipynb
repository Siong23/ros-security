{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW-pjcd9etDH",
        "outputId": "1b0ee973-7813-4be9-fa0a-11be807b7330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features order: ['Src Port', 'Dst Port', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\n"
          ]
        }
      ],
      "source": [
        "from joblib import load\n",
        "import pandas as pd\n",
        "\n",
        "# Load model, scaler, and features\n",
        "model = load(\"model.joblib\")\n",
        "scaler = load(\"scaler.joblib\")   # skip if you didn’t save scaler\n",
        "\n",
        "with open(\"features.txt\") as f:\n",
        "    features = [line.strip() for line in f]\n",
        "\n",
        "print(\"Features order:\", features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model expects: ['Src Port', 'Dst Port', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean'] ...\n",
            "CSV has: ['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts'] ...\n",
            "Missing in CSV: set()\n",
            "Extra in CSV: {'Flow ID', 'Dst IP', 'Timestamp', 'Label', 'Protocol', 'Src IP'}\n"
          ]
        }
      ],
      "source": [
        "# Load your new CSV data\n",
        "new_data = pd.read_csv(\"C:\\\\Users\\\\Asus\\\\Documents\\\\MMU\\\\degree sem 7 intern\\\\Reports\\\\ROS-SCRIPTS\\\\! important\\\\acmirf-new\\\\NavBot25.csv\")\n",
        "\n",
        "# Compare model features vs CSV columns\n",
        "print(\"Model expects:\", features[:10], \"...\")  # first 10 expected features\n",
        "print(\"CSV has:\", list(new_data.columns)[:10], \"...\")  # first 10 columns from CSV\n",
        "\n",
        "missing = set(features) - set(new_data.columns)\n",
        "extra = set(new_data.columns) - set(features)\n",
        "\n",
        "print(\"Missing in CSV:\", missing)\n",
        "print(\"Extra in CSV:\", extra)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "W94QFhJngc9Y"
      },
      "outputs": [],
      "source": [
        "# Force reordering of columns to match training order\n",
        "new_data = new_data.reindex(columns=features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "o0lgvbMigWyq"
      },
      "outputs": [],
      "source": [
        "# Keep only model's features (drop all others)\n",
        "new_data = new_data.loc[:, new_data.columns.intersection(features)]\n",
        "\n",
        "# Reorder columns to exactly match training\n",
        "new_data = new_data.reindex(columns=features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3sKIUE0gjzX",
        "outputId": "071923e0-b684-4aa1-b7eb-8355a0138deb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expected features: ['Src Port', 'Dst Port', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\n",
            "New data columns : ['Src Port', 'Dst Port', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\n",
            "Shape of new_data: (192213, 78)\n"
          ]
        }
      ],
      "source": [
        "print(\"Expected features:\", features)\n",
        "print(\"New data columns :\", list(new_data.columns))\n",
        "print(\"Shape of new_data:\", new_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "cX-FYFrPgzp8"
      },
      "outputs": [],
      "source": [
        "new_data = new_data[features].copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjf1pWNBg0V7",
        "outputId": "0566457c-c2e2-4fe7-c047-9030cdf90a5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training features: ['Src Port', 'Dst Port', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\n",
            "New data columns: ['Src Port', 'Dst Port', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\n",
            "Same? True\n"
          ]
        }
      ],
      "source": [
        "# Clean up column names (remove hidden spaces etc.)\n",
        "new_data.columns = new_data.columns.str.strip()\n",
        "\n",
        "# Now force subset to ONLY training features\n",
        "new_data = new_data.loc[:, features]\n",
        "\n",
        "# Confirm\n",
        "print(\"Training features:\", features)\n",
        "print(\"New data columns:\", list(new_data.columns))\n",
        "print(\"Same?\", features == list(new_data.columns))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExIDi6Nlg6Zv",
        "outputId": "a68faaa8-00e9-48a0-f07d-b655f1c60e98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scaler feature names: ['Dst Port', 'Src Port', 'Bwd Header Len', 'Bwd Pkts/s', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Pkt Len Mean', 'Flow Pkts/s', 'Pkt Size Avg', 'Flow Duration', 'Pkt Len Std', 'Pkt Len Var', 'Flow IAT Mean', 'Bwd IAT Max', 'Subflow Bwd Byts', 'TotLen Bwd Pkts', 'Bwd Seg Size Avg', 'Bwd Pkt Len Mean', 'Flow IAT Max', 'Init Bwd Win Byts', 'Pkt Len Max', 'Flow Byts/s', 'Fwd Pkts/s', 'Fwd Header Len', 'Flow IAT Std', 'Subflow Bwd Pkts', 'Tot Bwd Pkts', 'Bwd IAT Min', 'Bwd Pkt Len Max', 'Bwd IAT Std', 'Tot Fwd Pkts', 'Subflow Fwd Pkts', 'Bwd Pkt Len Std', 'Flow IAT Min', 'Bwd Pkt Len Min', 'Fwd IAT Mean', 'Fwd IAT Tot', 'Down/Up Ratio', 'Idle Min', 'Idle Mean', 'Idle Max', 'Active Max', 'Fwd IAT Min', 'Active Mean', 'Fwd IAT Max', 'Active Min', 'SYN Flag Cnt', 'ACK Flag Cnt', 'Fwd IAT Std', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean', 'Fwd Seg Size Avg', 'Subflow Fwd Byts', 'TotLen Fwd Pkts', 'PSH Flag Cnt', 'Bwd PSH Flags', 'Idle Std', 'Active Std', 'Fwd Act Data Pkts', 'Fwd Pkt Len Min', 'Fwd Pkt Len Std', 'FIN Flag Cnt', 'Pkt Len Min']\n",
            "New data columns    : ['Src Port', 'Dst Port', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\n",
            "Match? False\n"
          ]
        }
      ],
      "source": [
        "print(\"Scaler feature names:\", list(scaler.feature_names_in_))\n",
        "print(\"New data columns    :\", list(new_data.columns))\n",
        "print(\"Match?\", list(scaler.feature_names_in_) == list(new_data.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "t_q9RQovg9rF"
      },
      "outputs": [],
      "source": [
        "new_data = new_data.loc[:, scaler.feature_names_in_]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60xSUDe9g_jB",
        "outputId": "c716a8a8-7a57-46fc-c0a0-cd974ab8a27f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing in CSV: set()\n",
            "Extra in CSV: {'Bwd Blk Rate Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Protocol', 'CWE Flag Count', 'Bwd Pkts/b Avg', 'Flow ID', 'Bwd Byts/b Avg', 'URG Flag Cnt', 'RST Flag Cnt', 'Fwd PSH Flags', 'Timestamp', 'Label', 'Bwd URG Flags', 'ECE Flag Cnt', 'Init Fwd Win Byts', 'Fwd Seg Size Min', 'Dst IP', 'Fwd Byts/b Avg', 'Fwd URG Flags', 'Src IP'}\n",
            "[0 0 0 ... 7 7 7]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from joblib import load\n",
        "\n",
        "# === Load model + scaler ===\n",
        "model = load(\"model.joblib\")\n",
        "scaler = load(\"scaler.joblib\")\n",
        "\n",
        "# Expected features from scaler\n",
        "expected_features = list(scaler.feature_names_in_)\n",
        "\n",
        "def prepare_and_predict(csv_file):\n",
        "    # 1. Load CSV\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # 2. Keep only required columns (drop timestamps or extras)\n",
        "    missing = set(expected_features) - set(df.columns)\n",
        "    extra = set(df.columns) - set(expected_features)\n",
        "    print(\"Missing in CSV:\", missing)\n",
        "    print(\"Extra in CSV:\", extra)\n",
        "\n",
        "    df = df.loc[:, expected_features]  # keep only what we need, in correct order\n",
        "\n",
        "    # 3. Clean data\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)  # replace inf with NaN\n",
        "    df = df.fillna(0)  # fill NaN with 0 (safe default, you can change strategy)\n",
        "\n",
        "    # 4. Scale\n",
        "    X_scaled = scaler.transform(df)\n",
        "\n",
        "    # 5. Predict\n",
        "    preds = model.predict(X_scaled)\n",
        "    return preds\n",
        "\n",
        "# === Run prediction on your new CSV ===\n",
        "predictions = prepare_and_predict(\"C:\\\\Users\\\\Asus\\\\Documents\\\\MMU\\\\degree sem 7 intern\\\\Reports\\\\ROS-SCRIPTS\\\\! important\\\\acmirf-new\\\\NavBot25.csv\") # replace data here <-----------------------\n",
        "print(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhrIDDZkhpSI",
        "outputId": "f95d5d85-751b-4179-d16e-20fd50063980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved cleaned CSV as cleaned_for_model.csv\n"
          ]
        }
      ],
      "source": [
        "def prepare_and_predict(csv_file, save_cleaned=False):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df = df.loc[:, expected_features]\n",
        "    df = df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "    if save_cleaned:\n",
        "        df.to_csv(\"cleaned_for_model.csv\", index=False)\n",
        "        print(\"Saved cleaned CSV as cleaned_for_model.csv\")\n",
        "\n",
        "    X_scaled = scaler.transform(df)\n",
        "    return model.predict(X_scaled)\n",
        "\n",
        "predictions = prepare_and_predict(\"C:\\\\Users\\\\Asus\\\\Documents\\\\MMU\\\\degree sem 7 intern\\\\Reports\\\\ROS-SCRIPTS\\\\! important\\\\acmirf-new\\\\NavBot25.csv\", save_cleaned=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "2U2ugmtNh7Ef"
      },
      "outputs": [],
      "source": [
        "def prepare_and_predict(csv_file, save_cleaned=False):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df = df.loc[:, expected_features]\n",
        "    df = df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "    if save_cleaned:\n",
        "        df.to_csv(\"cleaned_for_model.csv\", index=False)\n",
        "        print(\"Saved cleaned CSV as cleaned_for_model.csv\")\n",
        "\n",
        "    X_scaled = scaler.transform(df)\n",
        "    preds = model.predict(X_scaled)\n",
        "\n",
        "    # Convert numeric predictions into labels\n",
        "    decoded_preds = [label_map.get(p, f\"Unknown({p})\") for p in preds]\n",
        "    return decoded_preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "vLdjFKz2h83m"
      },
      "outputs": [],
      "source": [
        "# Define label mapping (example — adjust if your classes differ!)\n",
        "label_map = {\n",
        "    0: \"BENIGN\",\n",
        "    1: \"Botnet\",\n",
        "    2: \"Brute Force\",\n",
        "    3: \"DDoS\",\n",
        "    4: \"DoS\",\n",
        "    5: \"Infiltration\",\n",
        "    6: \"PortScan\",\n",
        "    7: \"Web Attack\"\n",
        "}\n",
        "\n",
        "def prepare_and_predict(csv_file, save_cleaned=False):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df = df.loc[:, expected_features]\n",
        "    df = df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "    if save_cleaned:\n",
        "        df.to_csv(\"cleaned_for_model.csv\", index=False)\n",
        "        print(\"Saved cleaned CSV as cleaned_for_model.csv\")\n",
        "\n",
        "    X_scaled = scaler.transform(df)\n",
        "    preds = model.predict(X_scaled)\n",
        "\n",
        "    # Convert numeric predictions into labels\n",
        "    decoded_preds = [label_map.get(p, f\"Unknown({p})\") for p in preds]\n",
        "    return decoded_preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHII0icXibRm",
        "outputId": "55300213-4e8e-4c57-8e94-db67ba32dfc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved cleaned CSV as cleaned_for_model.csv\n",
            "['BENIGN', 'BENIGN', 'BENIGN', 'BENIGN', 'BENIGN', 'BENIGN', 'BENIGN', 'BENIGN', 'BENIGN', 'BENIGN']\n",
            "\n",
            "Summary of predictions:\n",
            "Counter({'BENIGN': 63019, 'PortScan': 30336, 'Botnet': 29888, 'Web Attack': 29084, 'Brute Force': 25912, 'DDoS': 6135, 'DoS': 4715, 'Infiltration': 3124})\n",
            "Mix of benign and malicious: 63019 benign, 129194 malicious\n"
          ]
        }
      ],
      "source": [
        "predictions = prepare_and_predict(\"C:\\\\Users\\\\Asus\\\\Documents\\\\MMU\\\\degree sem 7 intern\\\\Reports\\\\ROS-SCRIPTS\\\\! important\\\\acmirf-new\\\\NavBot25.csv\", save_cleaned=True)\n",
        "\n",
        "# Print first 10 results\n",
        "print(predictions[:10])\n",
        "\n",
        "# Count benign vs malicious\n",
        "from collections import Counter\n",
        "counts = Counter(predictions)\n",
        "\n",
        "print(\"\\nSummary of predictions:\")\n",
        "print(counts)\n",
        "\n",
        "if counts[\"BENIGN\"] == len(predictions):\n",
        "    print(\"✅ All traffic is benign.\")\n",
        "elif counts[\"BENIGN\"] == 0:\n",
        "    print(\"⚠️ All traffic is malicious.\")\n",
        "else:\n",
        "    print(f\"Mix of benign and malicious: {counts['BENIGN']} benign, {len(predictions)-counts['BENIGN']} malicious\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4_pTQqMleTi",
        "outputId": "0b8dcef9-5924-4ec2-a762-4ecadc571111"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved cleaned CSV as cleaned_for_model.csv\n",
            "['BENIGN', 'BENIGN', 'BENIGN', 'BENIGN', 'BENIGN', 'BENIGN', 'BENIGN', 'BENIGN', 'BENIGN', 'BENIGN']\n",
            "\n",
            "Summary of predictions:\n",
            "Counter({'BENIGN': 63019, 'PortScan': 30336, 'Botnet': 29888, 'Web Attack': 29084, 'Brute Force': 25912, 'DDoS': 6135, 'DoS': 4715, 'Infiltration': 3124})\n",
            "Mix of benign and malicious: 63019 benign, 129194 malicious\n"
          ]
        }
      ],
      "source": [
        "predictions = prepare_and_predict(\"C:\\\\Users\\\\Asus\\\\Documents\\\\MMU\\\\degree sem 7 intern\\\\Reports\\\\ROS-SCRIPTS\\\\! important\\\\acmirf-new\\\\NavBot25.csv\", save_cleaned=True)\n",
        "\n",
        "# Print first 10 results\n",
        "print(predictions[:10])\n",
        "\n",
        "# Count benign vs malicious\n",
        "from collections import Counter\n",
        "counts = Counter(predictions)\n",
        "\n",
        "print(\"\\nSummary of predictions:\")\n",
        "print(counts)\n",
        "\n",
        "if counts[\"BENIGN\"] == len(predictions):\n",
        "    print(\"✅ All traffic is benign.\")\n",
        "elif counts[\"BENIGN\"] == 0:\n",
        "    print(\"⚠️ All traffic is malicious.\")\n",
        "else:\n",
        "    print(f\"Mix of benign and malicious: {counts['BENIGN']} benign, {len(predictions)-counts['BENIGN']} malicious\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

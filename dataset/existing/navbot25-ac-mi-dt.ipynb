{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11670509,"sourceType":"datasetVersion","datasetId":7324106},{"sourceId":12891388,"sourceType":"datasetVersion","datasetId":8156220}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install scikit-learn imbalanced-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:11:21.514360Z","iopub.execute_input":"2025-08-28T03:11:21.515169Z","iopub.status.idle":"2025-08-28T03:14:42.801535Z","shell.execute_reply.started":"2025-08-28T03:11:21.515141Z","shell.execute_reply":"2025-08-28T03:14:42.800200Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d5782419550>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/scikit-learn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d57823e5250>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/scikit-learn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d57823e4510>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/scikit-learn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d57823a8350>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/scikit-learn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d57823a7590>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/scikit-learn/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement scikit-learn==1.5.1 (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for scikit-learn==1.5.1\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport glob\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.tree import plot_tree\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import mutual_info_classif, SelectKBest\nimport optuna\nfrom sklearn.decomposition import PCA","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.803976Z","iopub.execute_input":"2025-08-28T03:14:42.804290Z","iopub.status.idle":"2025-08-28T03:14:42.832039Z","shell.execute_reply.started":"2025-08-28T03:14:42.804264Z","shell.execute_reply":"2025-08-28T03:14:42.829481Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3663242123.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# process, as it may not be compiled yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     from . import (\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mcombine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mensemble\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/combine/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_smote_enn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTEENN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_smote_tomek\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTETomek\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/combine/_smote_enn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseOverSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneToOneFeatureMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_binarize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMETHODS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.utils._metadata_requests'"],"ename":"ModuleNotFoundError","evalue":"No module named 'sklearn.utils._metadata_requests'","output_type":"error"}],"execution_count":12},{"cell_type":"code","source":"# Load the dataset\nfile_path = \"/kaggle/input/navbot25/NavBot25.csv\"  \ndata = pd.read_csv(file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:54.488737Z","iopub.execute_input":"2025-08-28T03:14:54.489054Z","iopub.status.idle":"2025-08-28T03:14:57.334231Z","shell.execute_reply.started":"2025-08-28T03:14:54.489030Z","shell.execute_reply":"2025-08-28T03:14:57.333264Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Display dataset info\nprint(data.info())\nprint(data.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:15:01.082299Z","iopub.execute_input":"2025-08-28T03:15:01.082671Z","iopub.status.idle":"2025-08-28T03:15:01.221131Z","shell.execute_reply.started":"2025-08-28T03:15:01.082649Z","shell.execute_reply":"2025-08-28T03:15:01.220123Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 192213 entries, 0 to 192212\nData columns (total 84 columns):\n #   Column             Non-Null Count   Dtype  \n---  ------             --------------   -----  \n 0   Flow ID            192213 non-null  object \n 1   Src IP             192213 non-null  object \n 2   Src Port           192213 non-null  int64  \n 3   Dst IP             192213 non-null  object \n 4   Dst Port           192213 non-null  int64  \n 5   Protocol           192213 non-null  int64  \n 6   Timestamp          192213 non-null  object \n 7   Flow Duration      192213 non-null  int64  \n 8   Tot Fwd Pkts       192213 non-null  int64  \n 9   Tot Bwd Pkts       192213 non-null  int64  \n 10  TotLen Fwd Pkts    192213 non-null  int64  \n 11  TotLen Bwd Pkts    192213 non-null  int64  \n 12  Fwd Pkt Len Max    192213 non-null  int64  \n 13  Fwd Pkt Len Min    192213 non-null  int64  \n 14  Fwd Pkt Len Mean   192213 non-null  float64\n 15  Fwd Pkt Len Std    192213 non-null  float64\n 16  Bwd Pkt Len Max    192213 non-null  int64  \n 17  Bwd Pkt Len Min    192213 non-null  int64  \n 18  Bwd Pkt Len Mean   192213 non-null  float64\n 19  Bwd Pkt Len Std    192213 non-null  float64\n 20  Flow Byts/s        192213 non-null  float64\n 21  Flow Pkts/s        192213 non-null  float64\n 22  Flow IAT Mean      192213 non-null  float64\n 23  Flow IAT Std       192213 non-null  float64\n 24  Flow IAT Max       192213 non-null  int64  \n 25  Flow IAT Min       192213 non-null  int64  \n 26  Fwd IAT Tot        192213 non-null  int64  \n 27  Fwd IAT Mean       192213 non-null  float64\n 28  Fwd IAT Std        192213 non-null  float64\n 29  Fwd IAT Max        192213 non-null  int64  \n 30  Fwd IAT Min        192213 non-null  int64  \n 31  Bwd IAT Tot        192213 non-null  int64  \n 32  Bwd IAT Mean       192213 non-null  float64\n 33  Bwd IAT Std        192213 non-null  float64\n 34  Bwd IAT Max        192213 non-null  int64  \n 35  Bwd IAT Min        192213 non-null  int64  \n 36  Fwd PSH Flags      192213 non-null  int64  \n 37  Bwd PSH Flags      192213 non-null  int64  \n 38  Fwd URG Flags      192213 non-null  int64  \n 39  Bwd URG Flags      192213 non-null  int64  \n 40  Fwd Header Len     192213 non-null  int64  \n 41  Bwd Header Len     192213 non-null  int64  \n 42  Fwd Pkts/s         192213 non-null  float64\n 43  Bwd Pkts/s         192213 non-null  float64\n 44  Pkt Len Min        192213 non-null  int64  \n 45  Pkt Len Max        192213 non-null  int64  \n 46  Pkt Len Mean       192213 non-null  float64\n 47  Pkt Len Std        192213 non-null  float64\n 48  Pkt Len Var        192213 non-null  float64\n 49  FIN Flag Cnt       192213 non-null  int64  \n 50  SYN Flag Cnt       192213 non-null  int64  \n 51  RST Flag Cnt       192213 non-null  int64  \n 52  PSH Flag Cnt       192213 non-null  int64  \n 53  ACK Flag Cnt       192213 non-null  int64  \n 54  URG Flag Cnt       192213 non-null  int64  \n 55  CWE Flag Count     192213 non-null  int64  \n 56  ECE Flag Cnt       192213 non-null  int64  \n 57  Down/Up Ratio      192213 non-null  int64  \n 58  Pkt Size Avg       192213 non-null  float64\n 59  Fwd Seg Size Avg   192213 non-null  float64\n 60  Bwd Seg Size Avg   192213 non-null  float64\n 61  Fwd Byts/b Avg     192213 non-null  int64  \n 62  Fwd Pkts/b Avg     192213 non-null  int64  \n 63  Fwd Blk Rate Avg   192213 non-null  int64  \n 64  Bwd Byts/b Avg     192213 non-null  int64  \n 65  Bwd Pkts/b Avg     192213 non-null  int64  \n 66  Bwd Blk Rate Avg   192213 non-null  int64  \n 67  Subflow Fwd Pkts   192213 non-null  int64  \n 68  Subflow Fwd Byts   192213 non-null  int64  \n 69  Subflow Bwd Pkts   192213 non-null  int64  \n 70  Subflow Bwd Byts   192213 non-null  int64  \n 71  Init Fwd Win Byts  192213 non-null  int64  \n 72  Init Bwd Win Byts  192213 non-null  int64  \n 73  Fwd Act Data Pkts  192213 non-null  int64  \n 74  Fwd Seg Size Min   192213 non-null  int64  \n 75  Active Mean        192213 non-null  float64\n 76  Active Std         192213 non-null  float64\n 77  Active Max         192213 non-null  int64  \n 78  Active Min         192213 non-null  int64  \n 79  Idle Mean          192213 non-null  float64\n 80  Idle Std           192213 non-null  float64\n 81  Idle Max           192213 non-null  int64  \n 82  Idle Min           192213 non-null  int64  \n 83  Label              192213 non-null  object \ndtypes: float64(24), int64(55), object(5)\nmemory usage: 123.2+ MB\nNone\n                                     Flow ID         Src IP  Src Port  \\\n0  192.168.0.141-192.168.0.142-41983-50740-6  192.168.0.141     41983   \n1  192.168.0.141-192.168.0.142-41983-50748-6  192.168.0.141     41983   \n2  192.168.0.141-192.168.0.142-41983-46904-6  192.168.0.141     41983   \n3  192.168.0.141-192.168.0.142-41983-46890-6  192.168.0.141     41983   \n4  192.168.0.141-192.168.0.142-41983-46880-6  192.168.0.141     41983   \n\n          Dst IP  Dst Port  Protocol        Timestamp  Flow Duration  \\\n0  192.168.0.142     50740         6  27/4/2025 17:06         965262   \n1  192.168.0.142     50748         6  27/4/2025 17:06         965962   \n2  192.168.0.142     46904         6  27/4/2025 17:06         999392   \n3  192.168.0.142     46890         6  27/4/2025 17:06         965489   \n4  192.168.0.142     46880         6  27/4/2025 17:06         965379   \n\n   Tot Fwd Pkts  Tot Bwd Pkts  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n0            29            30  ...                 0          0.0         0.0   \n1            29            30  ...                 0          0.0         0.0   \n2            30            29  ...                 0          0.0         0.0   \n3            29            30  ...                 0          0.0         0.0   \n4            29            30  ...                 0          0.0         0.0   \n\n   Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min   Label  \n0           0           0        0.0       0.0         0         0  Normal  \n1           0           0        0.0       0.0         0         0  Normal  \n2           0           0        0.0       0.0         0         0  Normal  \n3           0           0        0.0       0.0         0         0  Normal  \n4           0           0        0.0       0.0         0         0  Normal  \n\n[5 rows x 84 columns]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"print(data['Label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.835749Z","iopub.status.idle":"2025-08-28T03:14:42.836050Z","shell.execute_reply.started":"2025-08-28T03:14:42.835922Z","shell.execute_reply":"2025-08-28T03:14:42.835934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define attack type mapping\nattack_mapping = {\n    \"Normal\": 0,\n    \"DoS Attack\": 1,\n    \"UnauthSub Attack\": 2,\n    \"SSH Bruteforce\": 3,\n    \"Pubflood\": 4,\n    \"Subflood\": 5,\n    \"Reverse Shell\": 6,\n    \"Port Scanning Attack\": 7\n}\n\n# Convert attack type names to numeric labels\ndata[\"Label\"] = data[\"Label\"].map(attack_mapping)\n\n# Drop rows with unmatched labels (if any)\ndata = data.dropna(subset=[\"Label\"])\n\n# Ensure labels are integers\ndata[\"Label\"] = data[\"Label\"].astype(int)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.837607Z","iopub.status.idle":"2025-08-28T03:14:42.837922Z","shell.execute_reply.started":"2025-08-28T03:14:42.837783Z","shell.execute_reply":"2025-08-28T03:14:42.837798Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop unnecessary columns\ncolumns_to_drop = ['Flow ID', 'Src IP', 'Dst IP', 'Protocol', 'Timestamp']\ndata = data.drop(columns=columns_to_drop, errors='ignore')\n\n# Check if any column is non-numeric\nnon_numeric_columns = data.select_dtypes(exclude=['number']).columns\nprint(\"Non-numeric columns:\", non_numeric_columns)\n\n# Handle missing values for numeric columns only\nnumeric_columns = data.select_dtypes(include=['number']).columns\ndata[numeric_columns] = data[numeric_columns].fillna(data[numeric_columns].mean())\n\n# Check the dataset again\nprint(data.info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.839177Z","iopub.status.idle":"2025-08-28T03:14:42.839586Z","shell.execute_reply.started":"2025-08-28T03:14:42.839395Z","shell.execute_reply":"2025-08-28T03:14:42.839413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split into features (X) and target (y)\nX = data.drop('Label', axis=1)  # Features\ny = data['Label']  # Target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.840927Z","iopub.status.idle":"2025-08-28T03:14:42.841232Z","shell.execute_reply.started":"2025-08-28T03:14:42.841071Z","shell.execute_reply":"2025-08-28T03:14:42.841084Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split into training and testing sets (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(\"Training set size:\", X_train.shape)\nprint(\"Testing set size:\", X_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.843034Z","iopub.status.idle":"2025-08-28T03:14:42.843368Z","shell.execute_reply.started":"2025-08-28T03:14:42.843187Z","shell.execute_reply":"2025-08-28T03:14:42.843199Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for NaN values\nprint(\"NaN values in X_train:\", np.isnan(X_train).sum().sum())\nprint(\"NaN values in X_test:\", np.isnan(X_test).sum().sum())\n\n# Check for infinity values\nprint(\"Infinity values in X_train:\", np.isinf(X_train).sum().sum())\nprint(\"Infinity values in X_test:\", np.isinf(X_test).sum().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.845304Z","iopub.status.idle":"2025-08-28T03:14:42.845700Z","shell.execute_reply.started":"2025-08-28T03:14:42.845499Z","shell.execute_reply":"2025-08-28T03:14:42.845515Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Replace NaN and infinity with the mean of the column\nX_train = X_train.replace([np.inf, -np.inf], np.nan)\nX_test = X_test.replace([np.inf, -np.inf], np.nan)\n\n# Fill NaN with column mean\nX_train = X_train.fillna(X_train.mean())\nX_test = X_test.fillna(X_test.mean())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.846786Z","iopub.status.idle":"2025-08-28T03:14:42.847142Z","shell.execute_reply.started":"2025-08-28T03:14:42.846968Z","shell.execute_reply":"2025-08-28T03:14:42.846983Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print original class distribution\nprint(\"Original class distribution:\")\nprint(y_train.value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.848231Z","iopub.status.idle":"2025-08-28T03:14:42.848589Z","shell.execute_reply.started":"2025-08-28T03:14:42.848403Z","shell.execute_reply":"2025-08-28T03:14:42.848418Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot class distribution before SMOTE\nplt.figure(figsize=(8, 6))\ny_train.value_counts().sort_index().plot(kind='bar', color='skyblue')\nplt.xlabel(\"Class Label\")\nplt.ylabel(\"Number of Samples\")\nplt.title(\"Class Distribution Before SMOTE\")\nplt.xticks([0, 1, 2, 3, 4, 5, 6, 7], ['Normal', 'DoS Attack', 'UnauthSub Attack', 'SSH Bruteforce', 'UnauthPub Attack', 'Subflood', 'Reverse Shell', 'Port Scanning Attack'])\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.849906Z","iopub.status.idle":"2025-08-28T03:14:42.850201Z","shell.execute_reply.started":"2025-08-28T03:14:42.850048Z","shell.execute_reply":"2025-08-28T03:14:42.850059Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply SMOTE to balance the training set\nsmote = SMOTE(random_state=42)\nX_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n\n# Check the class distribution after SMOTE\nprint(\"Class distribution after SMOTE:\")\nprint(y_train_balanced.value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.851213Z","iopub.status.idle":"2025-08-28T03:14:42.851474Z","shell.execute_reply.started":"2025-08-28T03:14:42.851346Z","shell.execute_reply":"2025-08-28T03:14:42.851360Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot class distribution after SMOTE\nplt.figure(figsize=(8, 6))\ny_train_balanced.value_counts().sort_index().plot(kind='bar', color='skyblue')\nplt.xlabel(\"Class Label\")\nplt.ylabel(\"Number of Samples\")\nplt.title(\"Class Distribution After SMOTE\")\nplt.xticks([0, 1, 2, 3, 4, 5, 6, 7], ['Normal', 'DoS Attack', 'UnauthSub Attack', 'SSH Bruteforce', 'UnauthPub Attack', 'Subflood', 'Reverse Shell', 'Port Scanning Attack'])\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.853250Z","iopub.status.idle":"2025-08-28T03:14:42.853614Z","shell.execute_reply.started":"2025-08-28T03:14:42.853424Z","shell.execute_reply":"2025-08-28T03:14:42.853451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def scale_data(X_train, X_test, scale_data=True):\n    \"\"\"\n    Scales the data if scale_data is True.\n    \"\"\"\n    if scale_data:\n        scaler = StandardScaler()\n        X_train_scaled = scaler.fit_transform(X_train)\n        X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n\n        X_test_scaled = scaler.transform(X_test)\n        X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n    else:\n        X_train_scaled = X_train\n        X_test_scaled = X_test\n\n    return X_train_scaled, X_test_scaled, scaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.854323Z","iopub.status.idle":"2025-08-28T03:14:42.854581Z","shell.execute_reply.started":"2025-08-28T03:14:42.854458Z","shell.execute_reply":"2025-08-28T03:14:42.854469Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_mutual_info(X_train_scaled, y_train):\n    \"\"\"\n    Computes mutual information (MI) scores for the features in X_train.\n    \"\"\"\n    mi_scores = mutual_info_classif(X_train_scaled, y_train, random_state=42)\n    \n    # Create MI DataFrame with rank\n    mi_df = pd.DataFrame({\n        'Feature': X_train_scaled.columns,\n        'MI_Score': mi_scores\n    }).sort_values('MI_Score', ascending=False).reset_index(drop=True)\n    mi_df['Rank'] = mi_df.index + 1\n\n    return mi_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.855861Z","iopub.status.idle":"2025-08-28T03:14:42.856141Z","shell.execute_reply.started":"2025-08-28T03:14:42.855991Z","shell.execute_reply":"2025-08-28T03:14:42.856000Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_top_features(mi_df, top_n=20):\n    \"\"\"\n    Plots the top_n features based on their Mutual Information (MI) scores.\n    \"\"\"\n    top_k = mi_df.head(top_n)\n    \n    plt.figure(figsize=(10, 8))\n    sns.barplot(x='MI_Score', y='Feature', data=top_k, palette='viridis')\n    plt.title(f'Top {top_n} Features by Mutual Information Score', fontsize=16)\n    plt.xlabel('Mutual Information Score', fontsize=12)\n    plt.ylabel('Feature', fontsize=12)\n    plt.tight_layout()\n    plt.show()\n\n# First, scale the data and get the scaler\nX_train_scaled, X_test_scaled, scaler = scale_data(X_train_balanced, X_test, scale_data=True)\n\n# Then, compute mutual information\nmi_df = compute_mutual_info(X_train_scaled, y_train_balanced)\n\n# Print Top 20 Features based on MI Scores\nprint(\"[INFO] Top 20 Features by Mutual Information Scores:\")\nprint(mi_df.head(20))\n\n# Plot the top 20 features\nplot_top_features(mi_df, top_n=20)\n\n# Select features based on the mutual information threshold\nselected_features = mi_df[mi_df['MI_Score'] >= 0.01]['Feature'].tolist()\n\n# Now select the features from the original data\nX_train_selected = X_train_balanced[selected_features]\nX_test_selected = X_test[selected_features]\n\n# Ensure X_train_selected has the same columns as X_test_selected\nX_train_selected = X_train_balanced[X_test_selected.columns]  # Align training data to test features\n\n# Apply scaling to both the train and test data using the same scaler (that was used previously)\nX_train_scaled = scaler.fit_transform(X_train_selected)  # Fit and transform the train data\nX_test_scaled = scaler.transform(X_test_selected)  # Transform the test data\n\n# Print total number of selected features and their names\nprint(f\"[INFO] Selected {len(selected_features)} Features:\")\nprint(selected_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.857620Z","iopub.status.idle":"2025-08-28T03:14:42.858025Z","shell.execute_reply.started":"2025-08-28T03:14:42.857830Z","shell.execute_reply":"2025-08-28T03:14:42.857856Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Perform PCA\npca = PCA()\npca.fit(X_train_scaled)\n\n# Get explained variance ratio and cumulative variance ratio\nexplained_variance_ratio = pca.explained_variance_ratio_\ncumulative_variance_ratio = explained_variance_ratio.cumsum()\n\n# Plot the cumulative explained variance ratio\nplt.plot(cumulative_variance_ratio, label='Cumulative Explained Variance')\n\n# Set a threshold (e.g. 95% variance explained)\nthreshold = 0.95\ncomponent_count = next((i for i, val in enumerate(cumulative_variance_ratio) if val >= threshold), len(cumulative_variance_ratio)-1)\n\n# Plot the vertical line\nplt.axvline(x=component_count, color='red', linestyle='--', label=f'{component_count+1} Components')\n\n# Label the plot\nplt.xlabel('Number of Components')\nplt.ylabel('Cumulative Explained Variance')\nplt.legend(loc='best')\nplt.title(f'Cumulative Explained Variance (Threshold: {threshold*100:.0f}%)')\n\n# Show plot\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.859076Z","iopub.status.idle":"2025-08-28T03:14:42.859473Z","shell.execute_reply.started":"2025-08-28T03:14:42.859273Z","shell.execute_reply":"2025-08-28T03:14:42.859289Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Metrics calculation function\ndef calculate_metrics(y_true, y_pred, conf_matrix):\n    tn, fp, fn, tp = conf_matrix.ravel()\n\n    accuracy = accuracy_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred)\n    recall = recall_score(y_true, y_pred)\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n    f1 = f1_score(y_true, y_pred)\n\n    metrics = {\n        \"Accuracy\": accuracy,\n        \"Precision\": precision,\n        \"Recall\": recall,\n        \"Specificity\": specificity,\n        \"F1-score\": f1\n    }\n\n    return metrics\n\ndef display_metrics(metrics):\n    for metric_name, metric_value in metrics.items():\n        print(f\"{metric_name.ljust(12)}: {metric_value * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.861046Z","iopub.status.idle":"2025-08-28T03:14:42.861580Z","shell.execute_reply.started":"2025-08-28T03:14:42.861243Z","shell.execute_reply":"2025-08-28T03:14:42.861258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # Train a base Decision Tree model before hyperparameter tuning\nprint(\"Training base Decision Tree model...\")\ndt_base = DecisionTreeClassifier(random_state=42)\ndt_base.fit(X_train_scaled, y_train_balanced)\ndt_base_preds = dt_base.predict(X_test_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.862538Z","iopub.status.idle":"2025-08-28T03:14:42.862912Z","shell.execute_reply.started":"2025-08-28T03:14:42.862735Z","shell.execute_reply":"2025-08-28T03:14:42.862751Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # Generate and display metrics and confusion matrix for base model\nprint(\"\\nBase Decision Tree Performance:\")\nprint(classification_report(y_test, dt_base_preds, digits=4))\nprint(f\"Accuracy: {accuracy_score(y_test, dt_base_preds):.4f}\")\n    \nconf_matrix_base = confusion_matrix(y_test, dt_base_preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.863900Z","iopub.status.idle":"2025-08-28T03:14:42.864261Z","shell.execute_reply.started":"2025-08-28T03:14:42.864087Z","shell.execute_reply":"2025-08-28T03:14:42.864103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display confusion matrix as count\nplt.figure(figsize=(15, 6))\nplt.subplot(1, 2, 1)\nsns.heatmap(conf_matrix_base, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['Normal', 'DoS Attack', 'UnauthSub Attack', 'SSH Bruteforce', 'UnauthPub Attack', 'Subflood', 'Reverse Shell', 'Port Scanning Attack'], yticklabels=['Normal', 'DoS Attack', 'UnauthSub Attack', 'SSH Bruteforce', 'UnauthPub Attack', 'Subflood', 'Reverse Shell', 'Port Scanning Attack'])\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix - Count (Base DT)')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.865279Z","iopub.status.idle":"2025-08-28T03:14:42.865568Z","shell.execute_reply.started":"2025-08-28T03:14:42.865430Z","shell.execute_reply":"2025-08-28T03:14:42.865444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the Optuna objective function\ndef objective(trial):\n    max_depth = trial.suggest_int('max_depth', 5, 50)\n    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n    \n    model = DecisionTreeClassifier(\n        max_depth=max_depth,\n        min_samples_split=min_samples_split,\n        min_samples_leaf=min_samples_leaf,\n        criterion=criterion,\n        random_state=42\n    )\n\n    try:\n        model.fit(X_train_scaled, y_train_balanced)\n        y_pred = model.predict(X_test_scaled)\n        score = f1_score(y_test, y_pred, average='macro')  # <-- FIXED HERE\n    except Exception as e:\n        print(f\"Exception in Optuna trial: {e}\")\n        return 0.0\n\n    return score\n\n# Run Optuna optimization\nprint(\"\\nStarting Optuna hyperparameter optimization with 15 trials...\")\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=15)\n\n# Best hyperparameters\nbest_params = study.best_params\nprint(f\"\\nBest hyperparameters found: {best_params}\")\n\n# Train final model\nprint(\"\\nTraining Decision Tree with optimized hyperparameters...\")\ndt_tuned = DecisionTreeClassifier(\n    max_depth=best_params['max_depth'],\n    min_samples_split=best_params['min_samples_split'],\n    min_samples_leaf=best_params['min_samples_leaf'],\n    criterion=best_params['criterion'],\n    random_state=42\n)\ndt_tuned.fit(X_train_scaled, y_train_balanced)\ndt_tuned_preds = dt_tuned.predict(X_test_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.866966Z","iopub.status.idle":"2025-08-28T03:14:42.867315Z","shell.execute_reply.started":"2025-08-28T03:14:42.867139Z","shell.execute_reply":"2025-08-28T03:14:42.867154Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train a new model with the best hyperparameters\nprint(\"\\nTraining Decision Tree with optimized hyperparameters...\")\ndt_tuned = DecisionTreeClassifier(\n    max_depth=best_params['max_depth'],\n    min_samples_split=best_params['min_samples_split'],\n    min_samples_leaf=best_params['min_samples_leaf'],\n    criterion=best_params['criterion'],\n    random_state=42\n)\ndt_tuned.fit(X_train_scaled, y_train_balanced)\ndt_tuned_preds = dt_tuned.predict(X_test_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.868418Z","iopub.status.idle":"2025-08-28T03:14:42.868718Z","shell.execute_reply.started":"2025-08-28T03:14:42.868576Z","shell.execute_reply":"2025-08-28T03:14:42.868587Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Get the confusion matrix\ncm = confusion_matrix(y_test, dt_tuned_preds)\n\n# Create a figure with two subplots\nplt.figure(figsize=(16, 7))\n\n# Plot 1: Confusion Matrix (Counts)\nplt.subplot(1, 2, 1)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.title('Confusion Matrix (Counts)', fontsize=15)\nplt.xlabel('Predicted Labels', fontsize=12)\nplt.ylabel('True Labels', fontsize=12)\n\n# Plot 2: Confusion Matrix (Percentages)\nplt.subplot(1, 2, 2)\ncm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\nsns.heatmap(cm_percent, annot=True, fmt='.1f', cmap='Blues', cbar=False)\nplt.title('Confusion Matrix (Percentages)', fontsize=15)\nplt.xlabel('Predicted Labels', fontsize=12)\nplt.ylabel('True Labels', fontsize=12)\n\nplt.tight_layout()\nplt.show()\n\n# Print classification report for additional metrics\nfrom sklearn.metrics import classification_report\nprint('\\nClassification Report:')\nprint(classification_report(y_test, dt_tuned_preds))\n\n# Print overall accuracy\nfrom sklearn.metrics import accuracy_score\nprint(f'\\nAccuracy: {accuracy_score(y_test, dt_tuned_preds):.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.869961Z","iopub.status.idle":"2025-08-28T03:14:42.870240Z","shell.execute_reply.started":"2025-08-28T03:14:42.870081Z","shell.execute_reply":"2025-08-28T03:14:42.870091Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Step 1: Perform 5-fold cross-validation\nprint(\"\\nPerforming 5-Fold Cross Validation...\")\ncv_scores = cross_val_score(dt_tuned, X_train_scaled, y_train_balanced, cv=5)\n\n# Step 2: Print cross-validation results\nprint(f\"Cross-validation scores for each fold: {cv_scores}\")\nprint(f\"Mean accuracy: {np.mean(cv_scores)}\")\nprint(f\"Standard deviation: {np.std(cv_scores)}\")\n\n# Step 3: Visualize the comparison between the folds\nplt.figure(figsize=(10, 6))\n\n# Plot for cross-validation scores\nplt.plot(range(1, 6), cv_scores, marker='o', label='Validation Accuracy', color='blue', linestyle='-', linewidth=2)\n\n# Optional: If you want to compare training accuracy, you can also plot it (assuming you have training data available)\ntrain_scores = [dt_tuned.fit(X_train_scaled, y_train_balanced).score(X_train_scaled, y_train_balanced) for _ in range(5)]  # Mock training accuracy for each fold\n\n# Plot training accuracy for comparison (optional)\nplt.plot(range(1, 6), train_scores, marker='x', label='Training Accuracy', color='red', linestyle='--', linewidth=2)\n\n# Labels and title\nplt.title('Comparison of Training and Validation Accuracy Across 5-Folds')\nplt.xlabel('Fold Number')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Show plot\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T03:14:42.871506Z","iopub.status.idle":"2025-08-28T03:14:42.871801Z","shell.execute_reply.started":"2025-08-28T03:14:42.871646Z","shell.execute_reply":"2025-08-28T03:14:42.871657Z"}},"outputs":[],"execution_count":null}]}